{
    "1": {
        "question": "Что такое Data Science?",
        "answer": "Data Science - это область информатики, которая явно занимается превращением данных в информацию и извлечением значимых инсайтов из них. Причина популярности Data Science заключается в том, что типы инсайтов, которые мы можем извлечь из доступных данных, привели к значительным инновациям в нескольких продуктах и компаниях. Используя эти инсайты, мы можем определить вкус определенного клиента, вероятность успешности продукта на конкретном рынке и т. д."
    },
    "2": {
        "question": "В чем разница между Data Analytics и Data Science?",
        "answer": "1. Data Analytics\n\n   * Data Analytics является подмножеством Data Science.\n   * Целью анализа данных является иллюстрация точных деталей полученных инсайтов.\n   * Требуются только базовые языки программирования.\n   * Фокусируется только на поиске решений.\n   * Задача аналитика данных - проанализировать данные для принятия решений.\n\n2. Data Science\n\n   * Data Science - это широкая технология, которая включает в себя различные подразделы, такие как Data Analytics, Data Mining, Data Visualization и т. д.\n   * Цель Data Science - обнаружить значимые инсайты в огромных наборах данных и получить наилучшие возможные решения для решения бизнес-проблем.\n   * Требуется знание продвинутых языков программирования, статистики и специальных алгоритмов машинного обучения.\n   * Data Science не только фокусируется на поиске решений, но и предсказывает будущее по прошлым шаблонам или инсайтам.\n   * Задача ученого по данным - предоставить понятные инсайты из необработанных данных."
    },
    "3": {
        "question": "В чем полезность Python?",
        "answer": "Python широко признается как исключительно выгодный язык программирования благодаря его универсальности и простоте. Его обширный спектр приложений и связанные с ним преимущества сделали его предпочтительным выбором среди разработчиков. Особенно выделяется Python своей читаемостью и дружественностью к пользователю.\n\nЕго синтаксис тщательно разработан для интуитивной и краткой работы, обеспечивая удобство в написании кода, его понимании и поддержке. Кроме того, Python предлагает обширную стандартную библиотеку, которая включает в себя разнообразные наборы предварительно созданных модулей и функций. Это богатство ресурсов значительно сокращает время и усилия, затрачиваемые разработчиками на выполнение рутинных программных задач."
    },
    "4": {
        "question": "Как полезен R в области науки о данных?",
        "answer": "Вот несколько способов, которыми R полезен в области науки о данных:\n\n* Манипуляция и анализ данных: R предлагает обширную коллекцию библиотек и функций, которые облегчают умелую манипуляцию данными, их преобразование и статистический анализ.\n* Статистическое моделирование и машинное обучение: R предлагает широкий спектр пакетов для продвинутого статистического моделирования и задач машинного обучения, что позволяет данным ученым создавать прогностические модели и выполнять сложные анализы.\n* Визуализация данных: Обширные библиотеки визуализации R позволяют создавать наглядные и содержательные графики, диаграммы и графики.\n* Воспроизводимые исследования: R поддерживает интеграцию кода, данных и документации, облегчая воспроизводимые рабочие процессы и обеспечивая прозрачность в проектах по науке о данных."
    },
    "5": {
        "question": "Что такое Обучение с Учителем (Supervised Learning)?",
        "answer": "Обучение с учителем - это подход машинного обучения, при котором алгоритм изучает размеченные обучающие данные для предсказания или классификации новых, невиданных данных. Он включает использование входных данных и соответствующих выходных меток, что позволяет алгоритму выявлять закономерности и взаимосвязи. Цель состоит в обобщении изученных закономерностей и точном предсказании выходных данных для новых входных данных на основе выученных закономерностей."
    },
    "6": {
        "question": "Что такое Обучение без Учителя (Unsupervised Learning)?",
        "answer": "Обучение без учителя - это подход машинного обучения, при котором алгоритм выявляет закономерности и структуры в неразмеченных данных, действуя без явного руководства или заранее определенных выходных меток. Его целью является выявление скрытых отношений, закономерностей и кластеров в данных. В отличие от обучения с учителем, алгоритм самостоятельно исследует данные, чтобы идентифицировать внутренние структуры и делать выводы, что ценно для исследовательского анализа данных и обнаружения новых инсайтов."
    },
    "7": {
        "question": "Что вы понимаете под Линейной Регрессией?",
        "answer": "Линейная регрессия помогает понять линейную зависимость между зависимыми и независимыми переменными. Линейная регрессия - это алгоритм обучения с учителем, который помогает найти линейную зависимость между двумя переменными. Одна переменная является предиктором или независимой переменной, а другая - ответом или зависимой переменной. В линейной регрессии мы пытаемся понять, как зависимая переменная изменяется относительно независимой переменной. Если есть только одна независимая переменная, то это называется простой линейной регрессией, а если независимых переменных больше одной, то это известно как множественная линейная регрессия."
    },
    "8": {
        "question": "Что вы понимаете под Логистической Регрессией?",
        "answer": "Логистическая регрессия - это алгоритм классификации, который может использоваться, когда зависимая переменная бинарна. Давайте рассмотрим пример. Здесь мы пытаемся определить, будет ли дождь или нет на основе температуры и влажности.\n\nТемпература и влажность являются независимыми переменными, а дождь - нашей зависимой переменной. Итак, алгоритм логистической регрессии фактически создает кривую S-образной формы.\n\nТаким образом, в логистической регрессии значение Y находится в диапазоне от 0 до 1. Вот как работает логистическая регрессия."
    },
    "9": {
        "question": "Что такое Матрица Недопонимания (Confusion Matrix)?",
        "answer": "Матрица недопонимания - это таблица, которая используется для оценки производительности модели. Она составляет таблицу фактических и предсказанных значений в виде матрицы 2×2.\n\nИстинно Положительные (d): Это обозначает все те записи, где фактические значения и предсказанные значения истинны. Таким образом, это обозначает все истинные положительные случаи. Ложно Отрицательные (c): Это обозначает все те записи, где фактические значения истинны, но предсказанные значения ложны. Ложно Положительные (b): В этом случае фактические значения ложны, но предсказанные значения истинны. Истинно Отрицательные (a): Здесь фактические значения ложны, а предсказанные значения также ложны. Таким образом, если вы хотите получить правильные значения, то правильные значения в основном будут представлять собой все истинные положительные и истинные отрицательные случаи. Вот как работает матрица недопонимания."
    },
    "10": {
        "question": "Что вы понимаете под понятиями 'истинно-положительная скорость' и 'ложно-положительная скорость'?",
        "answer": "Истинно-положительная скорость: В машинном обучении истинно-положительные скорости, также известные как чувствительность или полнота, используются для измерения процента фактических положительных результатов, которые правильно идентифицированы. Формула: \nИстинно-положительная скорость = Истинные положительные/Положительные\n\nЛожно-положительная скорость: Ложно-положительная скорость - это в основном вероятность ложного отклонения нулевой гипотезы для определенного теста. Ложно-положительная скорость рассчитывается как отношение количества отрицательных событий, ошибочно категоризированных как положительные (ложно-положительные), к общему числу фактических событий. Формула:\nЛожно-Положительная Скорость = Ложно-Положительные/Отрицательные."
    },
    "11": {
        "question": "В чем разница между наукой о данных и традиционным программированием приложений?",
        "answer": "Наука о данных принимает фундаментально другой подход к созданию систем, которые приносят ценность, чем традиционное развитие приложений.\n\nВ традиционных программных парадигмах мы анализировали ввод, определяли ожидаемый вывод и писали код, содержащий правила и операторы, необходимые для преобразования предоставленного ввода в ожидаемый вывод. Как можно себе представить, эти правила были не так просто написать, особенно для данных, которые даже компьютерам было трудно понять, например, изображения, видео и т. д.\n\nНаука о данных немного изменяет этот процесс. В ней нам нужен доступ к большим объемам данных, содержащим необходимые входные данные и их сопоставления с ожидаемыми выходными данными. Затем мы используем алгоритмы науки о данных, которые используют математический анализ для создания правил для сопоставления предоставленных входных данных с выходными данными.\n\nЭтот процесс генерации правил называется обучением. После обучения мы используем некоторые данные, которые были отложены до этапа обучения, чтобы протестировать и проверить точность системы. Сгенерированные правила - это своего рода черный ящик, и мы не можем понять, как входы преобразуются в выходы.\n\nОднако если точность достаточно высока, мы можем использовать систему (также называемую моделью).\n\nКак описано выше, в традиционном программировании нам приходилось написать правила для сопоставления входа и выхода, но в науке о данных правила создаются или изучаются автоматически из предоставленных данных. Это помогло решить некоторые действительно сложные проблемы, с которыми сталкивались несколько компаний."
    },
    "12": {
        "question": "В чем разница между данными в длинном формате и данными в широком формате?",
        "answer": "1. Длинные данные\n\n   * Данные в длинном формате имеют столбец для возможных типов переменных и столбец для значений этих переменных.\n   * Каждая строка в длинном формате представляет собой одну точку времени для каждого объекта. В результате каждая тема будет содержать много строк данных.\n   * Этот формат данных обычно используется в анализе R и для записи в журнальные файлы в конце каждого эксперимента.\n   * Длинный формат содержит значения, которые повторяются в первом столбце.\n   * Используйте df.melt(), чтобы преобразовать широкий формат в длинный формат.\n\n2. Широкие данные\n\n   * В то время как, Широкие данные имеют столбец для каждой переменной.\n   * Повторяющиеся ответы объекта будут в одной строке, причем каждый ответ будет в своем собственном столбце, в широком формате.\n   * Этот формат данных наиболее широко используется в манипуляциях с данными и статистических программах для анализа дисперсии с повторными измерениями и редко используется в анализе R.\n   * Широкий формат содержит значения, которые не повторяются в первом столбце.\n   * Используйте df.pivot().reset_index(), чтобы преобразовать длинный формат в широкий формат."
    },
    "13": {
        "question": "Упомяните некоторые техники, используемые для выборочного отбора. Каково главное преимущество выборочного отбора?",
        "answer": "Выборка определяется как процесс выбора выборки из группы людей или из любого конкретного вида в исследовательских целях. Это один из самых важных факторов, определяющих точность результатов исследования/опроса.\n\nВ основном существует два типа техник выборочного отбора:\n\nВероятностная выборка: Она включает в себя случайный выбор, который дает каждому элементу шанс быть выбранным. Вероятностная выборка имеет различные подтипы, описанные ниже:\n\n   * Простая случайная выборка\n   * Стратифицированная выборка\n   * Систематическая выборка\n   * Кластерная выборка\n   * Многоуровневая выборка\n\nНевероятностная выборка: Невероятностная выборка следует за невероятным выбором, что означает, что выбор делается на основе вашего удобства или любых других необходимых критериев. Это помогает легко собирать данные. Ниже приведены различные типы выборочной выборки:\n\n   * Удобная выборка\n   * Целевая выборка\n   * Квотная выборка\n   * Ссылочная/Снежный шаровой выбор"
    },
    "14": {
        "question": "Что такое смещение в науке о данных?",
        "answer": "Смещение - это тип ошибки, которая возникает в модели науки о данных из-за использования алгоритма, который не достаточно силен, чтобы захватить скрытые закономерности или тенденции, существующие в данных. Другими словами, эта ошибка возникает, когда данные слишком сложны для понимания алгоритмом, поэтому он строит модель, делающую простые предположения. Это приводит к снижению точности из-за недообучения. Алгоритмы, которые могут привести к высокому смещению, - это линейная регрессия, логистическая регрессия и т. д."
    },
    "15": {
        "question": "Что такое сокращение размерности?",
        "answer": "Сокращение размерности - это процесс преобразования набора данных с высоким количеством измерений (полей) в набор данных с меньшим количеством измерений. Это делается путем удаления некоторых полей или столбцов из набора данных. Однако это не делается хаотично. В этом процессе измерения или поля удаляются только после того, как убедятся, что оставшаяся информация будет достаточной для краткого описания подобной информации."
    },
    "16": {
        "question": "Почему R используется в визуализации данных?",
        "answer": "R предоставляет лучшую экосистему для анализа и визуализации данных с более чем 12 000 пакетов в репозиториях с открытым исходным кодом. У него огромная поддержка сообщества, что означает, что вы можете легко найти решение для ваших проблем на различных платформах, таких как StackOverflow.\n\nУ него лучшее управление данными и поддержка распределенных вычислений путем разделения операций между несколькими задачами и узлами, что в конечном итоге уменьшает сложность и время выполнения больших наборов данных."
    },
    "17": {
        "question": "Какие популярные библиотеки используются в науке о данных?",
        "answer": "Ниже приведены популярные библиотеки, используемые для извлечения, очистки, визуализации и развертывания моделей DS:\n\n* TensorFlow: Поддерживает параллельные вычисления с безупречным управлением библиотекой от Google.\n* SciPy: Главным образом используется для решения дифференциальных уравнений, многомерного программирования, манипуляции данными и визуализации через графики и диаграммы.\n* Pandas: Используется для реализации возможностей ETL (извлечение, преобразование и загрузка наборов данных) в бизнес-приложениях.\n* Matplotlib: Будучи бесплатным и с открытым исходным кодом, его можно использовать в качестве замены MATLAB, что приводит к лучшей производительности и низкому потреблению памяти.\n* PyTorch: Лучше всего подходит для проектов, включающих алгоритмы машинного обучения и глубокие нейронные сети."
    },
    "18": {
        "question": "Какие важные функции используются в науке о данных?",
        "answer": "В рамках науки о данных различные ключевые функции играют критически важные роли в различных задачах. Среди них две основные функции - функция стоимости и функция потерь.\n\nФункция стоимости: Также называемая целевой функцией, функция стоимости имеет существенное значение в алгоритмах машинного обучения, особенно в ситуациях оптимизации. Ее цель - количественно оценить различие между прогнозируемыми значениями и фактическими значениями. Минимизация функции стоимости включает в себя оптимизацию параметров или коэффициентов модели с целью достижения оптимального решения.\n\nФункция потерь: Функции потерь имеют значительное значение в усилиях по обучению с учителем. Они оценивают расхождение или ошибку между прогнозируемыми значениями и фактическими метками. Выбор конкретной функции потерь зависит от решаемой задачи, например, применение среднеквадратичной ошибки (MSE) для задач регрессии или потери перекрестной энтропии для задач классификации. Функция потерь руководит процессом оптимизации модели во время обучения, в конечном итоге укрепляя точность и общую производительность."
    },
    "19": {
        "question": "Что такое кросс-валидация k-fold?",
        "answer": "В кросс-валидации k-fold набор данных разбивается на k равных частей. Затем мы выполняем цикл по всему набору данных k раз. На каждой итерации цикла одна из k частей используется для тестирования, а другие k - 1 части используются для обучения. Используя кросс-валидацию k-fold, каждая из k частей набора данных используется для обучения и тестирования."
    },
    "20": {
        "question": "Объясните, как работает система рекомендаций.",
        "answer": "Система рекомендаций - это система, которую многие онлайн-платформы, ориентированные на потребителей и содержание, используют для генерации рекомендаций для пользователей из библиотеки доступного контента. Эти системы генерируют рекомендации на основе того, что они знают о вкусах пользователей из их действий на платформе.\n\nНапример, представьте, что у нас есть платформа для потоковой передачи фильмов, аналогичная Netflix или Amazon Prime. Если пользователь ранее смотрел и понравились фильмы из жанров боевиков и ужасов, это означает, что пользователю нравится смотреть фильмы этих жанров. В этом случае лучше рекомендовать такие фильмы этому конкретному пользователю. Эти рекомендации также могут быть сгенерированы на основе того, что нравится смотреть пользователям с аналогичными вкусами."
    },
    "21": {
        "question": "Что такое распределение Пуассона?",
        "answer": "Распределение Пуассона - это статистическое вероятностное распределение, используемое для представления возникновения событий в определенном интервале времени или пространства. Оно обычно используется для характеристики редких событий, которые происходят независимо и с постоянной средней скоростью, таких как количество входящих телефонных звонков за определенный час."
    },
    "22": {
        "question": "Что такое нормальное распределение?",
        "answer": "Распределение данных - это инструмент визуализации для анализа того, как данные распределены или распределены. Данные могут распределяться разными способами. Например, они могут иметь предвзятость влево или вправо, или все они могут быть перемешаны.\n\nДанные также могут распределяться вокруг центрального значения, например среднего, медианы и т. д. Этот вид распределения не имеет предвзятости ни влево, ни вправо и имеет форму колокола. Это распределение также имеет среднее, равное медиане. Такое распределение называется нормальным распределением."
    },
    "23": {
        "question": "Что такое глубокое обучение?",
        "answer": "Глубокое обучение - это разновидность машинного обучения, в которой нейронные сети используются для имитации структуры человеческого мозга, и, так же, как мозг учится от информации, машины также учатся от информации, предоставленной им.\n\nГлубокое обучение представляет собой продвинутую версию нейронных сетей, позволяющую машинам учиться на основе данных. В глубоком обучении нейронные сети состоят из множества скрытых слоев (отсюда и название 'глубокое' обучение), которые взаимосвязаны между собой, и выход предыдущего слоя является входом текущего слоя."
    },
    "24": {
        "question": "Что такое CNN (сверточная нейронная сеть)?",
        "answer": "Сверточная нейронная сеть (CNN) - это продвинутая архитектура глубокого обучения, разработанная специально для анализа визуальных данных, таких как изображения и видео. Она состоит из взаимосвязанных слоев нейронов, которые используют свертки для извлечения значимых признаков из входных данных. Сверточные нейронные сети проявляют выдающуюся эффективность в задачах, таких как классификация изображений, обнаружение объектов и распознавание изображений, благодаря их врожденной способности автономно изучать иерархические представления и улавливать пространственные отношения в данных, что исключает необходимость явного инжиниринга признаков."
    },
    "25": {
        "question": "Что такое RNN (рекуррентная нейронная сеть)?",
        "answer": "Рекуррентная нейронная сеть, или RNN, является видом алгоритма машинного обучения, который использует искусственную нейронную сеть. RNN используются для выявления закономерностей в последовательности данных, таких как временные ряды, фондовый рынок, температура и т. д. RNN являются разновидностью прямого распространения сети, в которой информация из одного слоя передается в другой слой, и каждый узел в сети выполняет математические операции над данными. Эти операции являются временными, то есть RNN сохраняют контекстную информацию о предыдущих вычислениях в сети. Он называется рекуррентным, потому что он выполняет те же операции с некоторыми данными каждый раз, когда они передаются. Однако результат может быть разным в зависимости от предыдущих вычислений и их результатов."
    },
    "26": {
        "question": "Объясните выборочный эффект.",
        "answer": "Выборочный эффект - это искажение, которое возникает в процессе выборки данных. Такой вид искажения возникает, когда выборка не является представительной для популяции, которая будет проанализирована в статистическом исследовании."
    },
    "27": {
        "question": "Между Python и R, какой из них вы выберете для анализа текста, и почему?",
        "answer": "Из-за следующих факторов Python превзойдет R при анализе текста:\n\n* Модуль Pandas в Python обеспечивает высокопроизводительные возможности анализа данных, а также простые в использовании структуры данных.\n\n* Python выполняет все виды анализа текста более быстро."
    },
    "28": {
        "question": "Объясните цель очистки данных",
        "answer": "Основная цель очистки данных - исправление или удаление неточных, поврежденных, неправильно отформатированных, дублированных или неполных данных из набора данных. Это часто приводит к лучшим результатам и более высокой отдаче от инвестиций в маркетинговые и коммуникационные усилия."
    },
    "29": {
        "question": "Что вы понимаете под Системой Рекомендаций? И укажите ее применение",
        "answer": "Системы рекомендаций - это подкласс систем фильтрации информации, предназначенных для прогнозирования предпочтений или оценок, которые пользователь дает продукту.\n\nСтраница рекомендаций продуктов Amazon - это пример использования системы рекомендаций. На основе истории поиска пользователя и предыдущих заказов эта область содержит продукты."
    },
    "30": {
        "question": "Что такое Градиентный Спуск?",
        "answer": "Итеративный оптимизационный процесс первого порядка, называемый градиентным спуском (GD), используется для поиска локального минимума и максимума заданной функции. Эта техника часто применяется в машинном обучении (ML) и глубоком обучении (DL) для минимизации функции стоимости/потерь (например, в линейной регрессии)."
    },
    "31": {
        "question": "Какие различные навыки необходимы, чтобы стать Data Scientist?",
        "answer": "Для того чтобы стать сертифицированным специалистом по обработке данных, необходимы следующие навыки:\n\n* Знание встроенных типов данных, таких как списки, кортежи, множества и связанные с ними.\n* Знание многомерных массивов NumPy.\n* Умение использовать Pandas и Dataframes.\n* Крепкое владение работой с векторами с одним элементом.\n* Практический опыт работы с Tableau и PowerBI."
    },
    "32": {
        "question": "Что такое TensorFlow?",
        "answer": "TensorFlow - это бесплатная библиотека программного обеспечения с открытым исходным кодом для машинного обучения и искусственного интеллекта. Он позволяет программистам создавать графы потоков данных, которые представляют собой представления потока данных между узлами обработки в графе."
    },
    "33": {
        "question": "Что такое Dropout?",
        "answer": "В науке о данных термин \"отсев\" относится к процессу случайного удаления видимых и скрытых узлов сети. Устраняя до 20% узлов, они избегают переобучения данных и создают необходимое пространство для итеративного сходимого процесса сети."
    },
    "34": {
        "question": "Укажите пять фреймворков глубокого обучения.",
        "answer": "Некоторые из фреймворков глубокого обучения:\n\n* Caffe\n* Keras\n* TensorFlow\n* Pytorch\n* Chainer\n* Microsoft Cognitive Toolkit"
    },
    "35": {
        "question": "Определите нейронные сети и их типы",
        "answer": "Нейронные сети - это вычислительные модели, которые извлекают свои принципы из структуры и функциональности человеческого мозга. Состоящие из взаимосвязанных искусственных нейронов, организованных в слои, нейронные сети обладают замечательными способностями к обучению и выявлению закономерностей в наборах данных. Следовательно, они играют ключевую роль в различных областях, включая распознавание образов, классификацию и оптимизацию, тем самым предоставляя неоценимые решения в области искусственного интеллекта.\n\nСуществует различные типы нейронных сетей, включая:\n\nПрямое распространение нейронных сетей (FFNN): Эти сети обеспечивают однонаправленный поток информации, прогрессирующий от ввода к выводу. Они часто применяются в задачах, связанных с распознаванием образов и классификацией.\n\n* Сверточные нейронные сети (CNN): Специально нацеленные на сетчатые данные, такие как изображения или видео, CNN используют сверточные слои для извлечения значимых характеристик. Их мастерство проявляется в задачах, таких как классификация изображений и обнаружение объектов.\n\n* Рекуррентные нейронные сети (RNN): RNN особенно хорошо справляются с последовательными данными, где текущий вывод зависит от предыдущих вводов. Их широко используют в областях, таких как языковое моделирование и анализ временных рядов.\n\n* Нейронные сети долгой краткосрочной памяти (LSTM): Эта вариация RNN решает проблему затухающих градиентов и успешно захватывает долгосрочные зависимости в данных. Сети LSTM находят широкое применение в областях, таких как распознавание речи и обработка естественного языка.\n\n* Генеративно-состязательные сети (GAN): GAN состоят из генератора и дискриминатора, которые обучаются в конкурентном режиме. Они применяются для генерации новых образцов данных и полезны для задач, таких как генерация изображений и синтез текста."
    },
    "36": {
        "question": "Что такое ROC-кривая?",
        "answer": "ROC означает характеристику операций приемника. Это в основном график между действительной положительной скоростью и ложной положительной скоростью, и он помогает нам определить правильный компромисс между действительной положительной скоростью и ложной положительной скоростью для различных порогов вероятности прогнозируемых значений. Таким образом, чем ближе кривая к верхнему левому углу, тем лучше модель. Иными словами, какая бы кривая ни имела большую площадь под ней, та модель будет лучше."
    },
    "37": {
        "question": "Как моделирование данных отличается от проектирования базы данных?",
        "answer": "Моделирование данных: Это можно рассматривать как первый этап проектирования базы данных. Моделирование данных создает концептуальную модель на основе взаимосвязи между различными моделями данных. Процесс включает движение от концептуального этапа к логической модели к физической схеме. Он включает систематический метод применения техник моделирования данных.\n\nПроектирование базы данных: Это процесс проектирования базы данных. Проектирование базы данных создает выходные данные, которые являются подробной моделью данных базы данных. Строго говоря, проектирование базы данных включает подробную логическую модель базы данных, но оно также может включать выбор физического дизайна и параметров хранения."
    },
    "38": {
        "question": "Что такое точность?",
        "answer": "Точность: Когда мы реализуем алгоритмы для классификации данных или извлечения информации, точность помогает нам получить часть положительных значений класса, которые положительно предсказаны. В основном, это измеряет точность правильных положительных прогнозов. Ниже приведена формула для расчета точности:\n\nprecision = (true positives)/(true positives + false positives)"
    },
    "39": {
        "question": "Что такое полнота?",
        "answer": "Полнота: Это набор всех положительных прогнозов из общего числа положительных случаев. Полнота помогает нам идентифицировать неправильно классифицированные положительные прогнозы. Мы используем нижеприведенную формулу для расчета полноты:\n\nrecall = (true positives)/(true positives + false negatives)"
    },
    "40": {
        "question": "Что такое p-значение?",
        "answer": "P-значение - это мера статистической важности наблюдения. Это вероятность, которая показывает значимость вывода для данных. Мы вычисляем p-значение, чтобы знать статистику теста модели. Обычно это помогает нам определить, можем ли мы принять или отвергнуть нулевую гипотезу."
    },
    "41": {
        "question": "Зачем мы используем p-значение?",
        "answer": "Мы используем p-значение, чтобы понять, действительно ли данные описывают наблюдаемый эффект или нет. Мы используем нижеприведенную формулу для расчета p-значения для эффекта ‘E’ и нулевой гипотезы ‘H0’ истинно:\n\nP Value = P(E | H0)"
    },
    "42": {
        "question": "В чем разница между ошибкой и остаточной ошибкой?",
        "answer": "Ошибка возникает в значениях, в то время как предсказание дает нам разницу между наблюдаемыми значениями и истинными значениями набора данных. В то время как остаточная ошибка - это разница между наблюдаемыми значениями и предсказанными значениями. Причина, по которой мы используем остаточную ошибку для оценки производительности алгоритма, заключается в том, что истинные значения никогда не известны. Поэтому мы используем наблюдаемые значения для измерения ошибки с использованием остатков. Это помогает нам получить точную оценку ошибки."
    },
    "43": {
        "question": "Как связаны Data Science и машинное обучение?",
        "answer": "Data Science и машинное обучение - это два термина, которые тесно связаны, но часто понимаются неправильно. Оба они имеют дело с данными. Однако есть некоторые фундаментальные различия, которые показывают, как они отличаются друг от друга.\n\nData Science - это обширная область, которая имеет дело с большими объемами данных и позволяет извлекать из этих данных инсайты. Весь процесс Data Science заботится о нескольких этапах, связанных с извлечением инсайтов из доступных данных. Этот процесс включает важные шаги, такие как сбор данных, анализ данных, манипуляция данными, визуализация данных и т. д.\n\nМашинное обучение, с другой стороны, можно рассматривать как подраздел Data Science. Оно также имеет дело с данными, но здесь мы сосредоточены исключительно на изучении того, как преобразовать обработанные данные в функциональную модель, которая может быть использована для сопоставления входов с выходами, например, модель, которая может ожидать изображение в качестве входных данных и сообщить нам, содержит ли это изображение цветок в качестве выходных данных.\n\nКороче говоря, Data Science занимается сбором данных, их обработкой и, наконец, извлечением из них инсайтов. Область Data Science, которая занимается созданием моделей с использованием алгоритмов, называется машинным обучением. Следовательно, машинное обучение является неотъемлемой частью Data Science."
    },
    "44": {
        "question": "Объясните унивариативный, бивариативный и многовариативный анализы.",
        "answer": "Когда мы занимаемся анализом данных, мы часто сталкиваемся с такими терминами, как унивариативный, бивариативный и многовариативный анализы. Давайте попробуем понять, что они означают.\n\n* Унивариативный анализ: Унивариативный анализ включает в себя анализ данных с только одной переменной или, другими словами, с одним столбцом или вектором данных. Этот анализ позволяет нам понять данные и извлечь из них закономерности и тенденции. Пример: Анализ веса группы людей.\n\n* Бивариативный анализ: Бивариативный анализ включает в себя анализ данных с точно двумя переменными или, другими словами, данные можно поместить в двухстолбцовую таблицу. Этот вид анализа позволяет нам определить взаимосвязь между переменными. Пример: Анализ данных, содержащих температуру и высоту.\n\n* Многовариативный анализ: Многовариативный анализ включает в себя анализ данных с более чем двумя переменными. Количество столбцов данных может быть любым, больше двух. Этот вид анализа позволяет нам определить влияние всех других переменных (входных переменных) на одну переменную (выходную переменную)."
    },
    "45": {
        "question": "Как мы можем обработать отсутствующие данные?",
        "answer": "Чтобы обработать отсутствующие данные, сначала нам нужно знать процент отсутствующих данных в конкретном столбце, чтобы мы могли выбрать соответствующую стратегию для решения этой ситуации.\n\nНапример, если в столбце большинство данных отсутствует, то лучшим вариантом будет удалить столбец, если у нас нет способов сделать обоснованные предположения о пропущенных значениях. Однако, если количество отсутствующих данных невелико, то у нас есть несколько стратегий для их заполнения.\n\nОдин из способов - заполнить их всеми значениями по умолчанию или значением, которое наиболее часто встречается в этом столбце, например, 0 или 1, и т. Д. Это может быть полезно, если большинство данных в этом столбце содержат эти значения.\n\nДругой способ - заполнить отсутствующие значения в столбце средним значением всех значений в этом столбце. Эта техника обычно предпочтительна, так как отсутствующие значения имеют более высокий шанс быть ближе к среднему, чем к моде.\n\nНаконец, если у нас есть огромный набор данных, и в нескольких строках отсутствуют значения в некоторых столбцах, то самый простой и быстрый способ - удалить эти столбцы. Поскольку набор данных большой, удаление нескольких столбцов не должно вызывать проблем."
    },
    "46": {
        "question": "Какова польза от снижения размерности?",
        "answer": "Снижение размерности уменьшает размеры и объем всего набора данных. Это убирает ненужные характеристики, сохраняя при этом общую информацию в данных неизменной. Уменьшение размерности приводит к более быстрой обработке данных.\n\nПричина, по которой данные с высокой размерностью считаются такими сложными для обработки, заключается в том, что это приводит к высокому временному потреблению при обработке данных и обучении модели на них. Сокращение размерности ускоряет этот процесс, удаляет шум и также повышает точность модели."
    },
    "47": {
        "question": "Что такое компромисс между смещением и разбросом в Data Science?",
        "answer": "При построении модели с использованием Data Science или машинного обучения нашей целью является построение такой модели, которая имеет низкое смещение и разброс. Мы знаем, что смещение и разброс - это обе ошибки, которые возникают из-за слишком упрощенной модели или из-за слишком сложной модели. Поэтому при построении модели цель получения высокой точности будет достигнута только в том случае, если мы осознаем компромисс между смещением и разбросом.\n\nСмещение - это ошибка, которая возникает, когда модель слишком проста, чтобы захватить закономерности в наборе данных. Для уменьшения смещения нам нужно сделать нашу модель более сложной. Хотя увеличение сложности модели может привести к уменьшению смещения, если мы делаем модель слишком сложной, она может стать слишком жесткой, что приведет к высокому разбросу. Таким образом, компромисс между смещением и разбросом заключается в том, что если мы увеличиваем сложность, смещение уменьшается, а разброс увеличивается, и если мы уменьшаем сложность, смещение увеличивается, а разброс уменьшается. Наша цель - найти точку, в которой наша модель достаточно сложна для обеспечения низкого смещения, но не настолько сложна, чтобы иметь высокий разброс."
    },
    "48": {
        "question": "Что такое RMSE?",
        "answer": "RMSE означает среднеквадратичное отклонение. Это мера точности в регрессии. RMSE позволяет нам вычислить величину ошибки, произведенной регрессионной моделью. Способ расчета RMSE следующий:\n\nСначала мы вычисляем ошибки в прогнозах, сделанных регрессионной моделью. Для этого мы вычисляем разницу между фактическими и предсказанными значениями. Затем мы возводим ошибки в квадрат.\n\nПосле этого мы вычисляем среднее значение квадратов ошибок, и, наконец, берем квадратный корень из среднего значения этих квадратов. Это число и есть RMSE, и модель с более низким значением RMSE считается более точной, то есть модель будет более точной."
    },
    "49": {
        "question": "Что такое ядерная функция в SVM?",
        "answer": "В алгоритме SVM ядерная функция - это специальная математическая функция. Проще говоря, ядерная функция берет данные на входе и преобразует их в требуемую форму. Это преобразование данных основано на чем-то, называемом ядерным трюком, отсюда и название ядерной функции. Используя ядерную функцию, мы можем преобразовать данные, которые не являются линейно разделимыми (не могут быть разделены с использованием прямой линии), в данные, которые линейно разделимы."
    },
    "50": {
        "question": "Как мы можем выбрать подходящее значение k в k-means?",
        "answer": "Выбор правильного значения k - важный аспект кластеризации k-means. Мы можем использовать метод локтя, чтобы выбрать подходящее значение k. Для этого мы запускаем алгоритм k-means для ряда значений, например, от 1 до 15. Для каждого значения k мы вычисляем средний балл. Этот балл также называется инерцией или межкластерной дисперсией.\n\nЭто рассчитывается как сумма квадратов расстояний всех значений в кластере. По мере того как k увеличивается от низкого значения до высокого значения, мы начинаем видеть резкое снижение значения инерции. После определенного значения k в этом диапазоне снижение значения инерции становится достаточно маленьким. Это значение k, которое мы должны выбрать для алгоритма кластеризации k-means."
    },
    "51": {
        "question": "Как мы можем справиться с выбросами?",
        "answer": "Выбросы можно обработать несколькими способами. Один из способов - удалить их. Мы можем удалять выбросы только в том случае, если они имеют значения, которые неверны или крайне экстремальны. Например, если в наборе данных с весами детей есть значение 98,6 градуса Фаренгейта, то это неверно. Теперь, если значение составляет 187 кг, то это крайне высокое значение, которое не пригодно для нашей модели.\n\nВ случае, если выбросы не настолько крайние, мы можем попробовать:\n\n* Использовать другой вид модели. Например, если мы использовали линейную модель, то мы можем выбрать нелинейную модель\n\n* Нормализация данных, которая сдвинет крайние значения ближе к другим точкам данных\n\n* Использование алгоритмов, которые не настолько чувствительны к выбросам, таких как случайный лес и т. Д."
    },
    "52": {
        "question": "Как рассчитать точность бинарного классификационного алгоритма с использованием его матрицы ошибок?",
        "answer": "В бинарном классификационном алгоритме у нас есть только два метки: Истинно и Ложь. Прежде чем мы сможем рассчитать точность, нам нужно понять несколько ключевых терминов:\n\n* Истинно-положительные: Количество наблюдений, правильно классифицированных как Истинно\n* Истинно-отрицательные: Количество наблюдений, правильно классифицированных как Ложь\n* Ложно-положительные: Количество наблюдений, неправильно классифицированных как Истинно\n* Ложно-отрицательные: Количество наблюдений, неправильно классифицированных как Ложь\n* Для расчета точности нам нужно разделить сумму правильно классифицированных наблюдений на общее количество наблюдений."
    },
    "53": {
        "question": "What is ensemble learning?",
        "answer": "When we are building models using Data Science and Machine Learning, our goal is to get a model that can understand the underlying trends in the training data and can make predictions or classifications with a high level of accuracy.\n\nHowever, sometimes some datasets are very complex, and it is difficult for one model to be able to grasp the underlying trends in these datasets. In such situations, we combine several individual models together to improve performance. This is what is called ensemble learning."
    },
    "54": {
        "question": "Explain collaborative filtering in recommender systems.",
        "answer": "Collaborative filtering is a technique used to build recommender systems. In this technique, to generate recommendations, we make use of data about the likes and dislikes of users similar to other users. This similarity is estimated based on several varying factors, such as age, gender, locality, etc.\n\nIf User A, similar to User B, watched and liked a movie, then that movie will be recommended to User B, and similarly, if User B watched and liked a movie, then that would be recommended to User A.\n\nIn other words, the content of the movie does not matter much. When recommending it to a user what matters is if other users similar to that particular user liked the content of the movie or not."
    },
    "55": {
        "question": "Explain content-based filtering in recommender systems.",
        "answer": "Content-based filtering is one of the techniques used to build recommender systems. In this technique, recommendations are generated by making use of the properties of the content that a user is interested in.\n\nFor example, if a user is watching movies belonging to the action and mystery genre and giving them good ratings, it is a clear indication that the user likes movies of this kind. If shown movies of a similar genre as recommendations, there is a higher probability that the user would like those recommendations as well.\n\nIn other words, here, the content of the movie is taken into consideration when generating recommendations for users."
    },
    "56": {
        "question": "Explain bagging in Data Science.",
        "answer": "Bagging is an ensemble learning method. It stands for bootstrap aggregating. In this technique, we generate some data using the bootstrap method, in which we use an already existing dataset and generate multiple samples of the N size. This bootstrapped data is then used to train multiple models in parallel, which makes the bagging model more robust than a simple model.\n\nOnce all the models are trained, then it’s time to make a prediction, we make predictions using all the trained models and then average the result in the case of regression, and for classification, we choose the result, generated by models, that have the highest frequency."
    },
    "57": {
        "question": "Explain boosting in data science.",
        "answer": "Boosting is one of the ensemble learning methods. Unlike bagging, it is not a technique used to parallelly train our models. In boosting, we create multiple models and sequentially train them by combining weak models iteratively in a way that training a new model depends on the models trained before it.\n\nIn doing so, we take the patterns learned by a previous model and test them on a dataset when training the new model. In each iteration, we give more importance to observations in the dataset that are incorrectly handled or predicted by previous models. Boosting is useful in reducing bias in models as well."
    },
    "58": {
        "question": "Explain stacking in data science.",
        "answer": "Just like bagging and boosting, stacking is also an ensemble learning method. In bagging and boosting, we could only combine weak models that used the same learning algorithms, e.g., logistic regression. These models are called homogeneous learners.\n\nHowever, in stacking, we can combine weak models that use different learning algorithms as well. These learners are called heterogeneous learners. Stacking works by training multiple (and different) weak models or learners and then using them together by training another model, called a meta-model, to make predictions based on the multiple outputs of predictions returned by these multiple weak models."
    },
    "59": {
        "question": "Explain how machine learning is different from deep learning.",
        "answer": "A field of computer science, machine learning is a subfield of data science that deals with using existing data to help systems automatically learn new skills to perform different tasks without having rules to be explicitly programmed.\n\nDeep Learning, on the other hand, is a field in machine learning that deals with building machine learning models using algorithms that try to imitate the process of how the human brain learns from the information in a system for it to attain new capabilities. In deep learning, we make heavy use of deeply connected neural networks with many layers."
    },
    "60": {
        "question": "Что означает слово «Наивный» в наивном Байесе?",
        "answer": "Наивный Байес - это алгоритм в области науки о данных. Он содержит слово «Байес» потому, что основан на теореме Байеса, которая имеет дело с вероятностью возникновения события при условии, что уже произошло другое событие.\n\nВ нем содержится «наивный», потому что он делает предположение, что каждая переменная в наборе данных независима от другой. Такое предположение нереалистично для данных реального мира. Однако, даже с этим предположением, он очень полезен для решения ряда сложных проблем, например, классификации спама почты и т. д."
    },
    "61": {
        "question": "Что такое батч-нормализация?",
        "answer": "Один из методов, направленных на улучшение функциональности и стабильности нейронной сети, это батч-нормализация. Для этого нормализуют входные данные на каждом уровне так, чтобы среднее значение активации выхода оставалось равным 0, а стандартное отклонение устанавливалось равным 1."
    },
    "62": {
        "question": "Что вы понимаете под кластерной выборкой и систематической выборкой?",
        "answer": "Кластерная выборка, также известная как вероятностный метод выборки, позволяет разделить популяцию на группы, такие как районы или школы, а затем выбрать представительную выборку из этих групп случайным образом. В каждом кластере должно быть присутствие небольшого представительства всей популяции.\n\nВероятностная стратегия выборки, называемая систематической выборкой, заключается в выборе людей из популяции через регулярные интервалы, например, каждого 15-го человека в списке населения. Популяция может быть организована случайным образом, чтобы имитировать преимущества простой случайной выборки."
    },
    "63": {
        "question": "Что такое вычислительный граф?",
        "answer": "Вычислительный граф - это ориентированный граф с переменными или операциями в качестве узлов. Переменные могут влиять на операции своим значением, и операции могут влиять на другие операции своим выводом. Таким образом, каждый узел в графе задает функцию переменных."
    },
    "64": {
        "question": "В чем разница между пакетным и стохастическим градиентным спуском?",
        "answer": "Различия между пакетным и стохастическим градиентным спуском следующие:\n\n1. Пакетный\n\n   * Помогает в вычислении градиента, используя весь набор данных.\n   * Требует времени для сходимости.\n   * Объем для анализа значителен.\n   * Обновляет веса редко.\n\n2. Стохастический градиентный спуск\n\n   * Помогает в вычислении градиента, используя только один образец.\n   * Требует меньше времени для сходимости.\n   * Объем для анализа ниже.\n   * Обновляет веса чаще."
    },
    "65": {
        "question": "Что такое функция активации?",
        "answer": "Функция активации - это функция, встроенная в искусственную нейронную сеть, чтобы помочь сети учиться сложным шаблонам во входных данных. В отличие от модели на основе нейронов, видимой в человеческих мозгах, функция активации определяет, какие сигналы должны быть отправлены следующему нейрону в конце концов."
    },
    "66": {
        "question": "Как построить модель случайного леса?",
        "answer": "Шаги построения модели случайного леса следующие: \n\n* Выберите n из набора данных из k записей. \n* Создайте отдельные деревья решений для каждого из n значений данных, учитываемых в анализе. Для каждого из них получается прогнозируемый результат. \n* Каждое из этих решений подвергается голосованию. \n* Окончательный результат определяется по тому, чей прогноз получил наибольшую поддержку."
    },
    "67": {
        "question": "Можно ли избежать переобучения модели? Если да, то как?",
        "answer": "На практике модели данных могут страдать от переобучения. Для этого могут применяться следующие стратегии:\n\n* Увеличение объема данных в анализируемом наборе данных, чтобы было проще различать связи между входными и выходными переменными. \n* Использование методов отбора признаков для выявления важных характеристик или параметров, которые необходимо изучить. \n* Использование стратегий регуляризации для уменьшения изменчивости результатов, которые порождает модель данных. \n* В редких случаях набор данных стабилизируется путем добавления небольшого количества шумных данных. Эта практика называется увеличением данных."
    },
    "68": {
        "question": "Что такое кросс-валидация?",
        "answer": "Кросс-валидация — это метод проверки модели, используемый для оценки обобщаемости результатов статистического анализа на другие наборы данных. Этот метод часто применяется, когда прогнозирование является основной целью и требуется оценить, насколько хорошо модель будет работать в реальных приложениях.\n\nС целью предотвращения переобучения и получения информации о том, как модель будет обобщаться на различные наборы данных, кросс-валидация стремится установить набор данных для проверки модели во время обучения (т.е. валидационный набор данных)."
    },
    "69": {
        "question": "Что такое дисперсия в Data Science?",
        "answer": "Дисперсия — это тип ошибки, которая возникает в модели Data Science, когда модель становится слишком сложной и изучает особенности данных вместе с шумом, который в них содержится. Этот вид ошибки может возникнуть, если алгоритм, используемый для обучения модели, имеет высокую сложность, даже если данные и подлежащие им образцы и тренды достаточно легко обнаруживаются. Это делает модель чрезвычайно чувствительной, работающей хорошо на обучающем наборе данных, но плохо на тестовом наборе данных и на любом другом наборе данных, который модель еще не видела. Дисперсия, как правило, приводит к плохой точности на тестировании и приводит к переобучению."
    },
    "70": {
        "question": "Что такое обрезка в алгоритме дерева решений?",
        "answer": "Обрезка дерева решений — это процесс удаления разделов дерева, которые не являются необходимыми или избыточными. Обрезка приводит к более компактному дереву решений, которое работает лучше и обеспечивает более высокую точность и скорость."
    },
    "71": {
        "question": "Какая информация получается в алгоритме дерева решений?",
        "answer": "При построении дерева решений на каждом шаге мы должны создать узел, который определяет, какой признак следует использовать для разделения данных, то есть, какой признак лучше всего разделяет наши данные для того, чтобы делать прогнозы. Это решение принимается с использованием информационного выигрыша, который является мерой того, насколько уменьшается энтропия, когда определенный признак используется для разделения данных. Признак, который дает наибольший информационный выигрыш, выбирается для разделения данных.\n\nДавайте рассмотрим практический пример, чтобы лучше понять, как информационный выигрыш функционирует в рамках алгоритма дерева решений. Представьте, что у нас есть набор данных, содержащий информацию о клиентах, такую как возраст, доход и история покупок. Наша цель - предсказать, совершит ли клиент покупку или нет.\n\nЧтобы определить, какой атрибут предоставляет наиболее ценную информацию, мы вычисляем информационный выигрыш для каждого атрибута. Если разделение данных на основе дохода приводит к подмножествам с значительно сниженной энтропией, это указывает на то, что доход играет ключевую роль в предсказании покупательского поведения. Следовательно, доход становится важным фактором при построении дерева решений, поскольку он предоставляет ценные идеи.\n\nМаксимизируя информационный выигрыш, алгоритм дерева решений выявляет атрибуты, которые эффективно снижают неопределенность и позволяют делать точные разделения. Этот процесс повышает предсказательную точность модели, обеспечивая обоснованные решения относительно покупок клиентов."
    },
    "72": {
        "question": "Как определить, являются ли данные временного ряда стационарными?",
        "answer": "Данные временного ряда считаются стационарными, когда дисперсия или среднее остаются постоянными со временем. Если дисперсия или среднее не изменяются в течение определенного времени в наборе данных, то мы можем сделать вывод, что в течение этого периода данные стационарны."
    },
    "73": {
        "question": "Что означает анализ корневых причин?",
        "answer": "Анализ корневых причин - это процесс выявления корневых причин, которые приводят к определенным сбоям или отказам. Фактор считается корневой причиной, если, устраняя его, последовательность операций, приводящая к сбое, ошибке или нежелательному результату, начинает работать правильно. Анализ корневых причин - это техника, которая изначально была разработана и использовалась при анализе промышленных аварий, но сейчас она используется в широком спектре областей."
    },
    "74": {
        "question": "Что такое A/B-тестирование?",
        "answer": "A/B-тестирование - это вид статистического тестирования гипотез для случайных экспериментов с двумя переменными. Эти переменные обозначаются как A и B. A/B-тестирование используется, когда мы хотим протестировать новую функцию в продукте. В A/B-тесте мы предоставляем пользователям два варианта продукта, и мы обозначаем эти варианты как A и B.\n\nВариант A может быть продуктом с добавленной новой функцией, а вариант B - продуктом без новой функции. После использования пользователями этих двух продуктов мы фиксируем их оценки продукта.\n\nЕсли оценка продукта варианта A статистически и значимо выше, то новая функция считается улучшением и полезной и принимается. В противном случае новая функция удаляется из продукта."
    },
    "75": {
        "question": "Из методов коллаборативной фильтрации и фильтрации на основе контента, какой считается лучшим, и почему?",
        "answer": "Фильтрация на основе контента считается более предпочтительной по сравнению с коллаборативной фильтрацией для создания рекомендаций. Это не означает, что коллаборативная фильтрация создает плохие рекомендации.\n\nОднако, поскольку коллаборативная фильтрация основана на предпочтениях и антипатиях других пользователей, на нее нельзя сильно полагаться. Кроме того, предпочтения и антипатии пользователей могут измениться в будущем.\n\nНапример, может быть фильм, который пользователю нравится прямо сейчас, но который он не любил 10 лет назад. Более того, пользователи, похожие по некоторым признакам, могут иметь разные вкусы в контенте, который предоставляет платформа.\n\nВ случае фильтрации на основе контента мы используем собственные предпочтения и антипатии пользователей, которые являются более надежными и дают более положительные результаты. Вот почему платформы, такие как Netflix, Amazon Prime, Spotify и др., используют фильтрацию на основе контента для создания рекомендаций для своих пользователей."
    },
    "76": {
        "question": "Что такое обучение с подкреплением?",
        "answer": "Обучение с подкреплением - это разновидность машинного обучения, которая занимается созданием программных агентов, выполняющих действия для достижения наибольших накопленных наград.\n\nВознаграждение здесь используется для того, чтобы модель знала (во время обучения), приводит ли конкретное действие к достижению или приближает к цели. Например, если мы создаем модель машинного обучения, которая играет в видеоигру, вознаграждение будет либо очки, набранные во время игры, либо уровень, достигнутый в ней.\n\nОбучение с подкреплением используется для создания таких агентов, которые могут принимать решения в реальном мире, направленные на достижение четко определенной цели."
    },
    "77": {
        "question": "Объясните векторизацию TF/IDF.",
        "answer": "Выражение 'TF/IDF' означает частота термина - обратная частота документа. Это числовая мера, которая позволяет определить, насколько важно слово для документа в коллекции документов, называемой корпусом. TF/IDF часто используется в текстовом анализе и информационном поиске."
    },
    "78": {
        "question": "Какие предположения необходимы для линейной регрессии?",
        "answer": "Существует несколько предположений, необходимых для линейной регрессии. Они следующие:\n\n* Данные, которые являются выборкой из генеральной совокупности, используемой для обучения модели, должны быть репрезентативными для генеральной совокупности.\n* Связь между независимыми переменными и средним значением зависимых переменных линейна.\n* Дисперсия остатков будет одинаковой для любого значения независимой переменной. Она также обозначается как X.\n* Каждое наблюдение является независимым от всех других наблюдений.\n* Для любого значения независимой переменной независимая переменная имеет нормальное распределение."
    },
    "79": {
        "question": "Что происходит, когда нарушаются некоторые предположения, необходимые для линейной регрессии?",
        "answer": "Эти предположения могут быть нарушены слабо (т.е. некоторые незначительные нарушения) или сильно (т.е. большинство данных имеют нарушения). Оба этих нарушения окажут различное воздействие на модель линейной регрессии.\n\nСильные нарушения этих предположений делают результаты абсолютно ненадежными. Легкие нарушения этих предположений приводят к увеличению смещения или разброса результатов."
    },
    "80": {
        "question": "Как справиться с несбалансированной бинарной классификацией?",
        "answer": "Ниже приведены следующие моменты, которые научат вас справляться с несбалансированной бинарной классификацией:\n\n* Используйте другие формулы для определения производительности модели, такие как точность/полнота, F1-оценка и т. д.\n* Пересэмплирование данных с использованием стратегий, таких как недосэмплирование (уменьшение размера выборки большего класса), пересэмплирование (увеличение размера выборки меньшего класса с помощью повторения, SMOTE и другие аналогичные стратегии) и так далее.\n* Используется кросс-валидация методом k-fold\n* Используйте ансамблирование так, чтобы каждое дерево решений учитывало только часть большего класса и полную выборку меньшего класса."
    },
    "81": {
        "question": "Какой метод перекрестной проверки следует использовать для набора данных временных рядов?",
        "answer": "Вместо использования кросс-валидации методом k-fold, следует помнить, что временной ряд фундаментально организован по хронологическому порядку и не состоит из случайно распределенных данных. Используйте подходы, такие как прямое цепное разбиение, при котором моделируется предыдущие данные, а затем рассматриваются данные впереди, при работе с данными временных рядов."
    },
    "82": {
        "question": "Как можно объявить данные временного ряда стационарными?",
        "answer": "Временной ряд считается стационарным, когда его основные составляющие не меняются со временем. Эти переменные могут быть дисперсией или средним. Статические временные ряды не проявляют ни трендов, ни сезонных эффектов. Для моделей науки о данных требуются данные из стационарных временных рядов."
    },
    "83": {
        "question": "В чем разница между точечной оценкой и доверительным интервалом?",
        "answer": "Точечная оценка: Конкретное число, известное как точечная оценка, предоставляет оценку параметра генеральной совокупности. Оценка максимального правдоподобия и метод моментов - два распространенных метода, используемых для создания точечных оценок параметра генеральной совокупности.\n\nДоверительный интервал: Доверительный интервал предоставляет диапазон значений, в котором с наибольшей вероятностью содержится параметр генеральной совокупности. Он также показывает вероятность того, что параметр генеральной совокупности может быть найден в этом определенном периоде времени. Вероятность или сходство выражается коэффициентом доверия (или уровнем доверия), который обозначается как 1-альфа. Уровень значимости обозначается альфой."
    },
    "84": {
        "question": "Определите термины KPI, прирост, подгонка модели, устойчивость и DOE.",
        "answer": "* KPI: KPI означает ключевой показатель эффективности, который оценивает, насколько успешно компания достигает своих целей.\n* Прирост: Прирост - это показатель эффективности целевой модели по сравнению с моделью случайного выбора. Прирост измеряет, насколько хорошо модель предсказывает по сравнению с отсутствием модели.\n* Подгонка модели: Это описывает, насколько хорошо предложенная модель соответствует имеющимся данным.\n* Устойчивость: Это относится к тому, насколько хорошо система может управлять изменениями и вариациями.\n* DOE: DOE относится к задаче проектирования с целью описания и объяснения изменчивости информации в предполагаемых условиях для отражения переменных."
    },
    "85": {
        "question": "Что такое LLMs?",
        "answer": "Большие языковые модели, сокращенно LLMs, - это сложные модели искусственного интеллекта, разработанные для обработки и генерации текста, напоминающего человеческий язык на основе полученного ввода. Они используют передовые техники, такие как глубокое обучение, особенно нейронные сети, для понимания и создания языковых шаблонов, что позволяет им отвечать на вопросы, вести разговоры и предоставлять информацию по широкому спектру тематик.\nLLMs проходят обучение с использованием обширных наборов текстовых данных из различных источников, включая книги, веб-сайты и другие текстовые материалы. Благодаря этому обучению они приобретают способность распознавать образцы, понимать контекст и генерировать логичные и контекстно соответствующие ответы.\nПримечательные примеры LLMs, такие как ChatGPT на основе архитектуры GPT-3.5, прошли обучение на обширных и разнообразных наборах данных для предоставления точной и ценной информации в различных областях. Эти модели обладают возможностями понимания естественного языка и могут выполнять различные задачи, такие как перевод языка, генерация контента и завершение текста.\nИх универсальность позволяет им помогать пользователям в различных запросах и задачах, что делает их ценными инструментами во многих областях, включая образование, обслуживание клиентов, создание контента и исследования."
    },
    "86": {
        "question": "Что такое трансформер в машинном обучении?",
        "answer": "В рамках машинного обучения термин \"трансформер\" обозначает архитектуру нейронной сети, которая получила значительное признание, в основном в области задач обработки естественного языка (NLP). Его введение произошло в ключевой научной статье под названием \"Внимание - все, что вам нужно\", написанной Васвани и др. в 2017 году. С тех пор трансформер стал фундаментальной структурой во множестве приложений в области NLP.\n\nАрхитектура трансформера специально разработана для преодоления ограничений, с которыми сталкиваются традиционные рекуррентные нейронные сети (RNN) при работе с последовательными данными, такими как предложения или документы. В отличие от RNN, трансформеры не зависят от последовательной обработки и обладают возможностью параллельных вычислений, тем самым обеспечивая повышенную эффективность и масштабируемость."
    }
}